{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dgl.data.CoraGraphDataset(verbose=False)\n",
    "g = dataset[0]\n",
    "num_class = dataset.num_classes\n",
    "# get node feature\n",
    "feat = g.ndata[\"feat\"]\n",
    "# get data split\n",
    "\n",
    "train_mask = g.ndata[\"train_mask\"]\n",
    "val_mask = g.ndata[\"val_mask\"]\n",
    "test_mask = g.ndata[\"test_mask\"]\n",
    "# get labels\n",
    "label = g.ndata[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.where(feat != 0)\n",
    "selected_feat = feat[indices[0], indices[1]]\n",
    "selected_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl import LapPE\n",
    "\n",
    "transform3 = LapPE(k=3, feat_name=\"eigvec\", eigval_name=\"eigval\", padding=False)\n",
    "g = train_dataset[0][0]\n",
    "\n",
    "g3 = transform3(g)\n",
    "print(g3.ndata[\"eigval\"])\n",
    "print(g3.ndata[\"eigvec\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = torch.randint(1, 8, (4, 4, 2))\n",
    "max_path_length = 5\n",
    "path_length = path.shape[2]\n",
    "p1d = ( max_path_length - path_length,0)\n",
    "F.pad(path, p1d, \"constant\", 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dgl.data.ZINCDataset(mode=\"train\")\n",
    "valid_dataset = dgl.data.ZINCDataset(mode=\"valid\")\n",
    "test_dataset = dgl.data.ZINCDataset(mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.randperm(len(train_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_train_dataset = [train_dataset[index] for index in indices]\n",
    "shuffled_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from centralityencoding import CentralityEncoder\n",
    "from spaceencoding import SpatialEncoder\n",
    "from edgeencoding import EdgeEncoder\n",
    "from encoder import Encoder\n",
    "\n",
    "class Graphormer(nn.Module):\n",
    "    \"\"\"\n",
    "    Graphormer model for graph representation learning.\n",
    "\n",
    "    Args:\n",
    "        regrees_output_dim (int): Regression output dimension.\n",
    "        edge_dim (int): Edge dimension.\n",
    "        num_atoms (int): Maximum number of atoms in batch graphs.\n",
    "        max_in_degree (int): Maximum in-degree in batch graphs.\n",
    "        max_out_degree (int): Maximum out-degree in batch graphs.\n",
    "        num_spatial (int): Maximum distance in batch graphs between two nodes.\n",
    "        multi_hop_max_dist (int): Maximum multi-hop distance in batch graphs.\n",
    "        num_encoder_layers (int): Number of encoder layers.\n",
    "        embedding_dim (int): Embedding dimension.\n",
    "        ffn_embedding_dim (int): Feed-forward network embedding dimension.\n",
    "        num_attention_heads (int): Number of attention heads.\n",
    "        dropout (float): Dropout rate.\n",
    "        pre_layernorm (bool): Whether to use pre-layer normalization.\n",
    "        activation_fn (nn.Module): Activation function.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        regrees_output_dim=1,\n",
    "        edge_dim=1,\n",
    "        num_atoms=0,\n",
    "        max_in_degree=0,\n",
    "        max_out_degree=0,\n",
    "        num_spatial=0,\n",
    "        multi_hop_max_dist=0,\n",
    "        num_encoder_layers=12,\n",
    "        embedding_dim=80,\n",
    "        ffn_embedding_dim=80,\n",
    "        num_attention_heads=8,\n",
    "        dropout=0.1,\n",
    "        pre_layernorm=True,\n",
    "        activation_fn=nn.GELU(),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_heads = num_attention_heads\n",
    "        self.atom_encoder = nn.Embedding(num_atoms + 1, embedding_dim, padding_idx=0)\n",
    "        self.graph_token = nn.Embedding(1, embedding_dim)\n",
    "        self.degree_encoder = CentralityEncoder(\n",
    "            max_in_degree=max_in_degree,\n",
    "            max_out_degree=max_out_degree,\n",
    "            embedding_dim=embedding_dim,\n",
    "        )\n",
    "        self.path_encoder = EdgeEncoder(\n",
    "            max_len=multi_hop_max_dist,\n",
    "            feat_dim=edge_dim,\n",
    "            num_heads=num_attention_heads,\n",
    "        )\n",
    "        self.spatial_encoder = SpatialEncoder(\n",
    "            max_dist=num_spatial, num_heads=num_attention_heads\n",
    "        )\n",
    "        self.graph_token_virtual_distance = nn.Embedding(1, num_attention_heads)\n",
    "        self.emb_layer_norm = nn.LayerNorm(self.embedding_dim)\n",
    "        self.layers = nn.ModuleList([])\n",
    "        self.layers.extend(\n",
    "            [\n",
    "                Encoder(\n",
    "                    hidden_size=embedding_dim,\n",
    "                    ffn_out_size=ffn_embedding_dim,\n",
    "                    attention_dropout=dropout,\n",
    "                    num_heads=num_attention_heads,\n",
    "                )\n",
    "                for _ in range(num_encoder_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.lm_head_transform_weight = nn.Linear(\n",
    "            self.embedding_dim, self.embedding_dim\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(self.embedding_dim)\n",
    "        self.activation_fn = activation_fn\n",
    "        self.embed_out = nn.Linear(self.embedding_dim, regrees_output_dim, bias=False)\n",
    "        self.lm_output_learned_bias = nn.Parameter(th.zeros(regrees_output_dim))\n",
    "\n",
    "    def reset_output_layer_parameters(self):\n",
    "        \"\"\"\n",
    "        Reset the parameters of the output layer.\n",
    "        \"\"\"\n",
    "        self.lm_output_learned_bias = nn.Parameter(th.zeros(1))\n",
    "        self.embed_out.reset_parameters()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        node_feat,\n",
    "        in_degree,\n",
    "        out_degree,\n",
    "        path_data,\n",
    "        dist,\n",
    "        attn_mask=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Forward pass for the Graphormer model.\n",
    "\n",
    "        Args:\n",
    "            node_feat (Tensor): Node feature tensor.\n",
    "            in_degree (Tensor): In-degree tensor.\n",
    "            out_degree (Tensor): Out-degree tensor.\n",
    "            path_data (Tensor): Path data tensor.\n",
    "            dist (Tensor): Distance tensor.\n",
    "            attn_mask (Tensor, optional): Attention mask tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Graph representation tensor.\n",
    "        \"\"\"\n",
    "        num_graphs, max_num_nodes, _ = node_feat.shape\n",
    "        deg_emb = self.degree_encoder(in_degree, out_degree)\n",
    "        node_feat = self.atom_encoder(node_feat.int()).sum(dim=-2)\n",
    "        node_feat = node_feat + deg_emb\n",
    "        graph_token_feat = self.graph_token.weight.unsqueeze(0).repeat(num_graphs, 1, 1)\n",
    "        x = th.cat([graph_token_feat, node_feat], dim=1)\n",
    "        attn_bias = th.zeros(\n",
    "            num_graphs,\n",
    "            max_num_nodes + 1,\n",
    "            max_num_nodes + 1,\n",
    "            self.num_heads,\n",
    "        )\n",
    "        path_encoding = self.path_encoder(dist, path_data)\n",
    "        spatial_encoding = self.spatial_encoder(dist)\n",
    "        attn_bias[:, 1:, 1:, :] = path_encoding + spatial_encoding\n",
    "        t = self.graph_token_virtual_distance.weight.reshape(1, 1, self.num_heads)\n",
    "        attn_bias[:, 1:, 0, :] = attn_bias[:, 1:, 0, :] + t\n",
    "        attn_bias[:, 0, :, :] = attn_bias[:, 0, :, :] + t\n",
    "        x = self.emb_layer_norm(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(\n",
    "                x,\n",
    "                att_mask=attn_mask,\n",
    "                att_bias=attn_bias,\n",
    "            )\n",
    "        graph_rep = x[:, 0, :]\n",
    "        graph_rep = self.layer_norm(\n",
    "            self.activation_fn(self.lm_head_transform_weight(graph_rep))\n",
    "        )\n",
    "        graph_rep = self.embed_out(graph_rep) + self.lm_output_learned_bias\n",
    "\n",
    "        return graph_rep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath: /home/a373k/Desktop/feb/Graphormer/zincdata.py\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import dgl\n",
    "import dgl.data\n",
    "\n",
    "class ZincDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    ZincDataset class for loading and processing the ZINC dataset.\n",
    "\n",
    "    This class handles the loading of the ZINC dataset, creating train, validation,\n",
    "    and test splits, and processing the graphs and labels.\n",
    "\n",
    "    Attributes:\n",
    "        train (list): List of training samples.\n",
    "        val (list): List of validation samples.\n",
    "        test (list): List of test samples.\n",
    "        max_dist (int): Maximum shortest path distance in the dataset.\n",
    "        max_in_degree (int): Maximum in-degree in the dataset.\n",
    "        max_out_degree (int): Maximum out-degree in the dataset.\n",
    "        max_num_nodes (int): Maximum number of nodes in the dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        train_dataset = dgl.data.ZINCDataset(mode=\"train\")[:256*14]\n",
    "        valid_dataset = dgl.data.ZINCDataset(mode=\"valid\")[:256*2]\n",
    "        test_dataset = dgl.data.ZINCDataset(mode=\"test\")[:256*2]\n",
    "\n",
    "        train_samples = [\n",
    "            (graph, label) for graph, label in zip(train_dataset[0], train_dataset[1])\n",
    "        ]\n",
    "        valid_samples = [\n",
    "            (graph, label) for graph, label in zip(valid_dataset[0], valid_dataset[1])\n",
    "        ]\n",
    "        test_samples = [\n",
    "            (graph, label) for graph, label in zip(test_dataset[0], test_dataset[1])\n",
    "        ]\n",
    "\n",
    "        self.train = train_samples\n",
    "        self.val = valid_samples\n",
    "        self.test = test_samples\n",
    "        self.max_dist = 0\n",
    "        self.max_in_degree = 0\n",
    "        self.max_out_degree = 0\n",
    "        self.max_num_nodes = 0\n",
    "\n",
    "        for dataset in [train_samples, valid_samples, test_samples]:\n",
    "            for g, labels in dataset:\n",
    "                spd, path = dgl.shortest_dist(g, return_paths=True)\n",
    "                g.ndata[\"spd\"] = spd\n",
    "                g.ndata[\"path\"] = path\n",
    "                dist_maxi = torch.max(spd).item()\n",
    "                if dist_maxi > self.max_dist:\n",
    "                    self.max_dist = dist_maxi\n",
    "                in_degree_maxi = torch.max(g.in_degrees()).item()\n",
    "                if in_degree_maxi > self.max_in_degree:\n",
    "                    self.max_in_degree = in_degree_maxi\n",
    "                out_degree_maxi = torch.max(g.out_degrees()).item()\n",
    "                if out_degree_maxi > self.max_out_degree:\n",
    "                    self.max_out_degree = out_degree_maxi\n",
    "                max_nodes = g.num_nodes()\n",
    "                if max_nodes > self.max_num_nodes:\n",
    "                    self.max_num_nodes = max_nodes\n",
    "\n",
    "    def collate(self, samples):\n",
    "        \"\"\"\n",
    "        Custom collate function to batch graphs, labels, and additional data.\n",
    "\n",
    "        Args:\n",
    "            samples (list): List of samples, where each sample is a tuple (graph, label).\n",
    "\n",
    "        Returns:\n",
    "            tuple: Batched data including labels, attention mask, node features,\n",
    "                   in-degrees, out-degrees, path data, and distances.\n",
    "        \"\"\"\n",
    "        graphs, labels = zip(*samples)\n",
    "        num_graphs = len(graphs)\n",
    "        num_nodes = [g.num_nodes() for g in graphs]\n",
    "        max_num_nodes = max(num_nodes)\n",
    "\n",
    "        attn_mask = torch.zeros(num_graphs, max_num_nodes + 1, max_num_nodes + 1)\n",
    "\n",
    "        node_feat = []\n",
    "        in_degree, out_degree = [], []\n",
    "        path_data = []\n",
    "\n",
    "        dist = -torch.ones((num_graphs, max_num_nodes, max_num_nodes), dtype=torch.long)\n",
    "\n",
    "        for i in range(num_graphs):\n",
    "            attn_mask[i, :, num_nodes[i] + 1 :] = 1\n",
    "            attn_mask[i, num_nodes[i] + 1 :, :] = 1\n",
    "\n",
    "            nd_feat = graphs[i].ndata[\"feat\"] + 1\n",
    "            if len(nd_feat.shape) == 1:\n",
    "                nd_feat = nd_feat.unsqueeze(1)\n",
    "            node_feat.append(nd_feat)\n",
    "\n",
    "            in_degree.append(\n",
    "                torch.clamp(graphs[i].in_degrees() + 1, min=0, max=self.max_in_degree)\n",
    "            )\n",
    "            out_degree.append(\n",
    "                torch.clamp(graphs[i].out_degrees() + 1, min=0, max=self.max_out_degree)\n",
    "            )\n",
    "\n",
    "            path = graphs[i].ndata[\"path\"]\n",
    "            path_len = path.size(dim=2)\n",
    "            max_len = self.max_dist\n",
    "            if (path_len >= max_len):\n",
    "                shortest_path = path[:, :, :max_len]\n",
    "            else:\n",
    "                p1d = (0, max_len - path_len)\n",
    "                shortest_path = F.pad(path, p1d, \"constant\", -1)\n",
    "            pad_num_nodes = max_num_nodes - num_nodes[i]\n",
    "            p3d = (0, 0, 0, pad_num_nodes, 0, pad_num_nodes)\n",
    "            shortest_path = F.pad(shortest_path, p3d, \"constant\", -1)\n",
    "\n",
    "            edata = graphs[i].edata[\"feat\"] + 1\n",
    "            if len(edata.shape) == 1:\n",
    "                edata = edata.unsqueeze(-1)\n",
    "            edata = torch.cat((edata, torch.zeros(1, edata.shape[1])), dim=0)\n",
    "            path_data.append(edata[shortest_path])\n",
    "\n",
    "            dist[i, : num_nodes[i], : num_nodes[i]] = graphs[i].ndata[\"spd\"]\n",
    "\n",
    "        node_feat = pad_sequence(node_feat, batch_first=True)\n",
    "        in_degree = pad_sequence(in_degree, batch_first=True)\n",
    "        out_degree = pad_sequence(out_degree, batch_first=True)\n",
    "\n",
    "        return (\n",
    "            torch.stack(labels).reshape(num_graphs, -1),\n",
    "            attn_mask,\n",
    "            node_feat,\n",
    "            in_degree,\n",
    "            out_degree,\n",
    "            torch.stack(path_data),\n",
    "            dist,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath: /home/a373k/Desktop/feb/Graphormer/centralityencoding.py\n",
    "import torch.nn as nn\n",
    "\n",
    "class CentralityEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Centrality Encoder for encoding node centrality features.\n",
    "\n",
    "    Args:\n",
    "        max_in_degree (int): Maximum in-degree of nodes.\n",
    "        max_out_degree (int): Maximum out-degree of nodes.\n",
    "        embedding_dim (int): Dimension of the embedding.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_in_degree, max_out_degree, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.in_degree_embedding_table = nn.Embedding(max_in_degree+1, embedding_dim, padding_idx=0)\n",
    "        self.out_degree_embedding_table = nn.Embedding(max_out_degree+1, embedding_dim, padding_idx=0)\n",
    "\n",
    "    def forward(self, in_degrees, out_degrees):\n",
    "        \"\"\"\n",
    "        Forward pass for the centrality encoder.\n",
    "\n",
    "        Args:\n",
    "            in_degrees (Tensor): In-degree tensor.\n",
    "            out_degrees (Tensor): Out-degree tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Centrality encoding tensor.\n",
    "        \"\"\"\n",
    "        z_in_degree = self.in_degree_embedding_table(in_degrees)\n",
    "        z_out_degree = self.out_degree_embedding_table(out_degrees)\n",
    "        z = z_in_degree + z_out_degree\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SpatialEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Spatial Encoder for encoding shortest path distances.\n",
    "\n",
    "    Args:\n",
    "        max_dist (int): Maximum distance for the shortest path.\n",
    "        num_heads (int): Number of attention heads.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_dist, num_heads=1):\n",
    "        super().__init__()\n",
    "        self.max_dist = max_dist\n",
    "        self.num_heads = num_heads\n",
    "        self.embedding_table = nn.Embedding(max_dist + 2, num_heads, padding_idx=0)\n",
    "\n",
    "    def forward(self, dist):\n",
    "        \"\"\"\n",
    "        Forward pass for the spatial encoder.\n",
    "\n",
    "        Args:\n",
    "            dist (Tensor): Shortest path distance tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Spatial encoding tensor.\n",
    "        \"\"\"\n",
    "        spatial_encoding = self.embedding_table(\n",
    "            th.clamp(\n",
    "                dist,\n",
    "                min=-1,\n",
    "                max=self.max_dist,\n",
    "            )\n",
    "            + 1\n",
    "        )\n",
    "        return spatial_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class EdgeEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Edge Encoder for encoding edge features along the shortest path.\n",
    "\n",
    "    Args:\n",
    "        max_len (int): Maximum length of the shortest path.\n",
    "        feat_dim (int): Dimension of the edge features.\n",
    "        num_heads (int): Number of attention heads.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_len, feat_dim, num_heads=1):\n",
    "        super().__init__()\n",
    "        self.max_len = max_len\n",
    "        self.feat_dim = feat_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.embedding_table = nn.Embedding(max_len * num_heads, feat_dim)\n",
    "\n",
    "    def forward(self, dist, path_data):\n",
    "        \"\"\"\n",
    "        Forward pass for the edge encoder.\n",
    "\n",
    "        Args:\n",
    "            dist (Tensor): Shortest path distance tensor.\n",
    "            path_data (Tensor): Edge feature tensor along the shortest path.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Path encoding tensor.\n",
    "        \"\"\"\n",
    "        shortest_distance = th.clamp(dist, min=1, max=self.max_len)\n",
    "        edge_embedding = self.embedding_table.weight.reshape(\n",
    "            self.max_len, self.num_heads, -1\n",
    "        )\n",
    "        path_encoding = th.div(\n",
    "            th.einsum(\"bxyld,lhd->bxyh\", path_data, edge_embedding).permute(\n",
    "                3, 0, 1, 2\n",
    "            ),\n",
    "            shortest_distance,\n",
    "        ).permute(1, 2, 3, 0)\n",
    "        return path_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath: /home/a373k/Desktop/feb/Graphormer/encoder.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Feed Forward Network used in the encoder.\n",
    "\n",
    "    Args:\n",
    "        hidden_size (int): Size of the hidden layer.\n",
    "        ffn_size (int): Size of the feed-forward layer.\n",
    "        encoder_dropout (float): Dropout rate.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, ffn_size, encoder_dropout):  # corrected typo here\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(hidden_size, ffn_size)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.layer2 = nn.Linear(ffn_size, hidden_size)\n",
    "        self.fnn_dropout = nn.Dropout(encoder_dropout)  # corrected typo here\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for the feed-forward network.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output tensor.\n",
    "        \"\"\"\n",
    "        x = self.layer1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.fnn_dropout(x)\n",
    "        return x\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-head Attention mechanism.\n",
    "\n",
    "    Args:\n",
    "        hidden_size (int): Size of the hidden layer.\n",
    "        attention_drop (float): Dropout rate for attention.\n",
    "        num_heads (int): Number of attention heads.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, attention_drop, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.att_size = hidden_size // num_heads\n",
    "        self.scale = self.att_size**-0.5\n",
    "        self.linear_q = nn.Linear(hidden_size, num_heads * self.att_size)\n",
    "        self.linear_k = nn.Linear(hidden_size, num_heads * self.att_size)\n",
    "        self.linear_v = nn.Linear(hidden_size, num_heads * self.att_size)\n",
    "        self.att_dropout = nn.Dropout(attention_drop)\n",
    "        self.output_layer = nn.Linear(num_heads * self.att_size, hidden_size)\n",
    "\n",
    "    def forward(self, h, att_bias=None, mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass for the attention mechanism.\n",
    "\n",
    "        Args:\n",
    "            h (Tensor): Input tensor.\n",
    "            att_bias (Tensor, optional): Attention bias tensor.\n",
    "            mask (Tensor, optional): Attention mask tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output tensor.\n",
    "        \"\"\"\n",
    "        q = self.linear_q(h)\n",
    "        k = self.linear_k(h)\n",
    "        v = self.linear_v(h)\n",
    "\n",
    "        q = q.view(q.size(0), q.size(1), self.num_heads, self.att_size).transpose(1, 2)\n",
    "        k = k.view(k.size(0), k.size(1), self.num_heads, self.att_size).transpose(1, 2)\n",
    "        v = v.view(v.size(0), v.size(1), self.num_heads, self.att_size).transpose(1, 2)\n",
    "\n",
    "        attn_weights = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n",
    "\n",
    "        if att_bias is not None:\n",
    "            attn_weights = attn_weights + att_bias\n",
    "\n",
    "        if mask is not None:\n",
    "            attn_weights = attn_weights.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        attn_weights = torch.softmax(attn_weights, dim=-1)\n",
    "        attn_weights = self.att_dropout(attn_weights)\n",
    "\n",
    "        attn_output = torch.matmul(attn_weights, v)\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(h.size(0), h.size(1), -1)\n",
    "        attn_output = self.output_layer(attn_output)\n",
    "\n",
    "        return attn_output\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder layer consisting of multi-head attention and feed-forward network.\n",
    "\n",
    "    Args:\n",
    "        hidden_size (int): Size of the hidden layer.\n",
    "        ffn_out_size (int): Size of the feed-forward layer.\n",
    "        attention_dropout (float): Dropout rate for attention.\n",
    "        num_heads (int): Number of attention heads.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, ffn_out_size, attention_dropout, num_heads):\n",
    "        super().__init__()\n",
    "        self.attention = Attention(hidden_size, attention_dropout, num_heads)\n",
    "        self.ffn = FeedForwardNetwork(hidden_size, ffn_out_size, attention_dropout)\n",
    "        self.layer_norm1 = nn.LayerNorm(hidden_size)\n",
    "        self.layer_norm2 = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, x, att_mask=None, att_bias=None):\n",
    "        \"\"\"\n",
    "        Forward pass for the encoder layer.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor.\n",
    "            att_mask (Tensor, optional): Attention mask tensor.\n",
    "            att_bias (Tensor, optional): Attention bias tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output tensor.\n",
    "        \"\"\"\n",
    "        h = self.layer_norm1(x)\n",
    "        h = self.attention(h, att_bias, att_mask)\n",
    "        h = self.dropout(h)\n",
    "        h = x + h\n",
    "\n",
    "        x = self.layer_norm2(h)\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = h + x\n",
    "\n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DGLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
